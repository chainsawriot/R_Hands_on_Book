{
  "hash": "9fad7502d3ebfbaefa0adc398f5d82e5",
  "result": {
    "markdown": "---\ntitle: \"Zusammenhänge bei mehr als zwei Variablen mit der multiplen Regression\"\nauthor: \"Stephanie Geise\"\ntoc: true\nnumber-sections: true\nhighlight-style: pygments\nformat:\n  html:\n    code-fold: false\n    code-line-numbers: true\n---\n\n\nDas Überprüfen von Zusammenhängen bei mehr als zwei Variablen\n\n# Das Überprüfen von Zusammenhängen bei mehr als zwei intervalskalierten Variablen\n\n## Analyselogik, Ziel und Einsatzgebiete einer multiplen Regressionsanalyse\n\nIn diesem Notebook gehen wir (wie angekündigt) zunächst näher auf die Prüfung der **Voraussetzungen einer Regressionsanalyse** ein. Dann lernen wir die **multiple lineare Regression** kennen, die es erlaubt, Zusammenhänge zwischen mehreren x-Variablen und einer y-Variablen zu analysieren.\n\n### Vorbereitung und Laden der Daten\n\nZunächst laden wir wieder die Pakete des tidyverse und das Pakete broom um die normale Ausgabe der Funktion lm (für die Berechnung linearer Modelle) in ein etwas anschaulicheres Format umwandeln zu können. Außerdem laden wir das Paket performance, dass wir für die Voraussetzungsprüfung brauchen, sowie die Pakete lmtest und sandwich, mit der wir fehlende Voraussetzungen korrigieren können (siehe unten). Die Regression rechnen wir wieder auf Basis des ESS8_vier_laender-Datensatzes, den wir entsprechend einlesen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\n#Laden der notwendigen Pakete\n#install.packages(\"lm.beta\")\n#install.packages(\"lmtest\")\n#install.packages(\"broom\") \n#install.packages(\"performance\")\n#install.packages(\"see\")\n#install.packages(\"sandwich\")\n\nlibrary(tidyverse)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.2     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n✔ purrr     1.0.1     \n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ dplyr::filter() masks stats::filter()\n✖ dplyr::lag()    masks stats::lag()\nℹ Use the conflicted package (<http://conflicted.r-lib.org/>) to force all conflicts to become errors\n```\n:::\n\n```{.r .cell-code}\nlibrary(lm.beta)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Paket 'lm.beta' wurde unter R Version 4.3.1 erstellt\n```\n:::\n\n```{.r .cell-code}\nlibrary(broom) # hier stecken einige Befehle zur Bereinigung der Daten und der Modelloutputs drin\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Paket 'broom' wurde unter R Version 4.3.1 erstellt\n```\n:::\n\n```{.r .cell-code}\nlibrary(performance)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Paket 'performance' wurde unter R Version 4.3.1 erstellt\n```\n:::\n\n```{.r .cell-code}\nlibrary(see)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Paket 'see' wurde unter R Version 4.3.1 erstellt\n```\n:::\n\n```{.r .cell-code}\nlibrary(lmtest)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Paket 'lmtest' wurde unter R Version 4.3.1 erstellt\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nLade nötiges Paket: zoo\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Paket 'zoo' wurde unter R Version 4.3.1 erstellt\n```\n:::\n\n::: {.cell-output .cell-output-stderr}\n```\n\nAttache Paket: 'zoo'\n\nDie folgenden Objekte sind maskiert von 'package:base':\n\n    as.Date, as.Date.numeric\n```\n:::\n\n```{.r .cell-code}\nlibrary(sandwich)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nWarning: Paket 'sandwich' wurde unter R Version 4.3.1 erstellt\n```\n:::\n\n```{.r .cell-code}\n#Daten laden und zum Datenobjekt \"daten\" zuweisen\ndaten <- read_rds(\"Datensatz/ESS8_vier_laender.rds\")\n\n#Visualisierungshintergrund der Grafiken in ggplot festlegen\ntheme_set(theme_minimal())\n\n# Anzeige der p-Werte als Zahlen mit Nachkommastellen einstellen\noptions(scipen = 999) \n```\n:::\n\n\n### Data Management\n\nAls abhängige Variable nutzen wir für unser Regressionsmodell wieder die Internetnutzung (netustm); als unabhängige Variablen schauen wir uns wie beim letzten Mal das Alter, sowie heute zusätzlich die Rezeptionszeit von politischen Nachrichten (nwspol) sowie das Geschlecht der Befragten (gndr) an. Damit der Output etwas nachvollziehbarer wird, benennen wir diese Variablen mit dem rename-Befehl um.\n\nDann setzen wir den drop_na-Befehl, um alle Fällen mit fehlenden Werten zu entfernen (in der Klammer spezifizieren wir wieder, auf welche Variablen sich der Befehl beziehen soll). Das modifizierte Datenset weisen wir einem neuen Datenobjekt zu: daten_mod2\n\nSchließlich nutze ich den slice_sample-Befehl, um aus unseren 8432 Fällen ein Zufallssample von n=100 Fällen zu ziehen, weil mir das die visuelle Interpretation erleichtert (diesen Befehl könnten wir hier auch weglassen, dann bekommen wir unten aber sehr sehr viele Datenpunkt in unserem Streudiagramm - probieren Sie es mal aus!)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndaten_mod <- daten %>% \n  rename(internetnutzung = netustm,\n         alter = agea,\n         politische_Nachrichtenrezeption = nwspol,\n         gender = gndr) %>% \n  drop_na(c(internetnutzung, alter, politische_Nachrichtenrezeption, gender)) %>% \nslice_sample(n = 100) \ndaten_mod\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 100 × 166\n        idno cntry gender alter marsts                   edubde1 eduade2 eduade3\n       <dbl> <fct> <fct>  <dbl> <fct>                    <fct>   <fct>   <fct>  \n 1 100001074 GB    Female    67 <NA>                     <NA>    <NA>    <NA>   \n 2      1044 SE    Male      62 None of these (NEVER ma… <NA>    <NA>    <NA>   \n 3  10007670 DE    Male      58 <NA>                     Fachho… Diplom… Laufba…\n 4 100002656 GB    Female    67 Legally married          <NA>    <NA>    <NA>   \n 5      1333 SE    Male      56 None of these (NEVER ma… <NA>    <NA>    <NA>   \n 6  10002266 DE    Male      21 None of these (NEVER ma… Abitur… Kein H… Kein b…\n 7 100000680 GB    Female    31 None of these (NEVER ma… <NA>    <NA>    <NA>   \n 8  10009262 DE    Female    47 None of these (NEVER ma… Mittle… Kein H… Abgesc…\n 9 100002806 GB    Male      57 None of these (NEVER ma… <NA>    <NA>    <NA>   \n10  10002009 DE    Female    76 <NA>                     Mittle… Kein H… Laufba…\n# ℹ 90 more rows\n# ℹ 158 more variables: politische_Nachrichtenrezeption <dbl>, netusoft <fct>,\n#   internetnutzung <dbl>, ppltrst <dbl>, pplfair <dbl>, pplhlp <dbl>,\n#   polintr <fct>, psppsgva <fct>, actrolga <fct>, psppipla <fct>,\n#   cptppola <fct>, trstprl <dbl>, trstlgl <dbl>, trstplc <dbl>, trstplt <dbl>,\n#   trstprt <dbl>, trstep <dbl>, trstun <dbl>, vote <fct>, prtvede1 <fct>,\n#   prtvede2 <fct>, contplt <fct>, wrkprty <fct>, wrkorg <fct>, badge <fct>, …\n```\n:::\n:::\n\n\n### Erinnerung: Einfache lineare Regression mit Alter als UV und Internetnutzung als AV mit lm (=linear models)\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel <- lm(internetnutzung ~ alter, data = daten_mod) \nsummary(model) # klassischer Output mit relevanten Kennzahlen\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = internetnutzung ~ alter, data = daten_mod)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-211.39  -97.38  -44.70   53.71  487.73 \n\nCoefficients:\n            Estimate Std. Error t value     Pr(>|t|)    \n(Intercept) 279.2690    45.2122   6.177 0.0000000149 ***\nalter        -1.9585     0.9218  -2.125       0.0361 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 150 on 98 degrees of freedom\nMultiple R-squared:  0.04404,\tAdjusted R-squared:  0.03428 \nF-statistic: 4.514 on 1 and 98 DF,  p-value: 0.03613\n```\n:::\n\n```{.r .cell-code}\n#summary(lm.beta(model)) # klassischer Output mit relevanten Kennzahlen erweitert um standardisierte beta-Koeffizienten\n```\n:::\n\n\nMit diesem Regressionsmodell haben wir übeprüft, ob das Alter die Internetnutzung erklären kann. Im Output sehen wir, dass das Alter einen signifikanten negativen Einfluss auf die Internetnutzung. Je älter ein Nutzer ist, desto weniger nutzt er das Internet. Die Regressionsanalyse lässt dabei auch eine Quantifizierung dieses Zusammenhangs zu: Mit jeder Einheit, in der die unabhängige Variable Alter steigt (hier: mit jedem Jahr Alter), nimmt die unabhängige Variable Internetnutzung um \"den Estimate-Wert\" in Messeinheiten (hier: -4.296 Minuten) ab. Dieser Zusammenhang ist mit p \\> .05 statistisch signifikant.\n\nSoweit die Wiederholung. Beginnen wir nun mit dem Teil A dieses Skripts, nämlich der Prüfung der **Voraussetzungen einer Regressionsanalyse**. Vielleicht wundern Sie sich, warum wir die Voraussetzungen erst im zweiten Schritt prüfen? Sie haben Recht: Eigentlich würden wir erst die Voraussetzungen prüfen, dann das Modell schätzen. Wenn wir unser Modell aber schon geschätzt haben, können wir Funktionen zur Prüfung der Voraussetzungen auf unser gesamtes Modell anwenden (bzw. auf das entsprechende Datenobjekt \"model\") - und das erspart uns eine Menge \"Handarbeit\" mit vielen kleinen Zwischenschritten. Zum Beispiel müssten wir für die Prüfung der Voraussetzungen, die die Residuen betreffen, diese erst einmal berechnen und in einer neuen Variable abspeichern. Es ist also weniger Aufwand, die Voraussetzungen ex post zu prüfen.\n\n### Erinnerung: Voraussetzungen der einfachen linearen Regression:\n\nBevor wir zum statistischen Teil kommen, lassen Sie uns noch einmal Revue passieren, was die wichtigsten Voraussetzungen der einfachen linearen Regression sind: 1) (quasi-)metrisches Skalenniveau 2) Linearität des Zusammenhangs zwischen x und y 3) Homoskedastizität der Residuen: Varianzen der Residuen der prognostizierten abhängigen Variablen sind gleich 4) Unabhängigkeit der Residuen: ansonsten Autokorrelation, die Aussagekraft reduziert 5) Normalverteilung der Residuen 6) Keine Ausreißer in den Daten, da schon einzelne Ausreißer einen sonst signifikanten Trend zunichte machen können (ggf. also eliminieren)\n\n### TEIL A: Prüfung der Voraussetzungen einer Regressionsanalyse\n\n#### Prüfung der Voraussetzungen 1 und 2: metrisches Skalenniveau & Linearität des Zusammenhangs\n\nOb 1.) die Variablen, die wir in das Regressionsmodell einbeziehen wollen (Alter, Internet-Nutzung) metrisch sind, und ob 2.) ein linearer Zusammenhang besteht, haben wir in der letzten Woche bereits überprüft. Für die Prüfung nach der Linearität des Zusammenhangs zwischen x und y hatten wir ein Streudiagramm mit der geschätzten Regressionsgeraden erzeugt.\n\n#### Prüfung der Voraussetzungen 3: Homoskedastizität der Residuen\n\nLineare Modelle setzen eine konstante Fehlervarianz (Homoskedastizität) voraus. Eine weitere Bedingung der Regressionanalyse ist also, dass die Varianzen der Residuen der prognostizierten abhängigen Variablen für alle Werte des Prädiktors gleich sind, so dass das Modell gleich gute Vorhersagen über alle Werte machen kann. Liegt Homoskedastizität vor, sind die Abweichungen der vorhergesagten Werte von den gemessenen Werten konstant gleich groß -- unabhängig wie hoch oder niedrig der Wert des Prädiktors ist. Das ist eine wichtige Voraussetzung, denn das Gegenteil - Heterokedastizität der Residuen - würde zur Ineffizienz unserer Schätzung führen! Denn die Standardfehler der Regressionskoeffizienten werden bei vorhandener Heteroskedastizität nach oben verzerrt geschätzt. Das Ergebnis wäre, dass unser Regressionsmodell mit seiner Vorhersage systematisch umso weiter daneben liegt, je größer der Prädiktorwert ist, für den wir die abhängige Variable schätzen wollen.\n\nDas klingt kompliziert? Kann sein, aber keine Panik: Mit der Funktionen *check_heteroscedasticity()* aus dem performance-package können wir sehr einfach prüfen, ob diese Annahme verletzt wurde.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_heteroscedasticity(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: Error variance appears to be homoscedastic (p = 0.329).\n```\n:::\n:::\n\n\nDie Interpretation des Outputs ist einfach, weil R hier uns eine sehr konkrete Aussage zur Überpüfung der Annahme macht: Bei grüner Schrift ist das Ergebnis in Ordnung, d.h. die Fehlervarianz scheint homoskedastisch, denn p wäre dann nicht signifikant. Bei roter Schrift ist die Fehlervarianz heteroskedastisch und p ist signifikant (p \\< 0.05). In diesem Fall liegt unser Regressionsmodell mit seiner Vorhersage systematisch umso weiter daneben, je größer der Prädiktorwert ist, für den wir die abhängige Variable schätzen wollen. Das müssen wir dann bei der Interpretation der Daten berücksichtigen.\n\nWie das ganze aussieht, können wir uns auch grafisch über die plot-Funktion anschauen. Dazu erzeugen wir ein Streudiagramm, das die vorhergesagten Werte und die Residuen enthält:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nplot(model, 1)\n```\n\n::: {.cell-output-display}\n![](Skript_7.3_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n\n```{.r .cell-code}\nplot(fitted.values(model), rstandard(model))\n```\n\n::: {.cell-output-display}\n![](Skript_7.3_files/figure-html/unnamed-chunk-2-2.png){width=672}\n:::\n:::\n\n\n#### Was sehen wir im Plot?\n\nZunächst betrachten wir die Streuung der Punkte im Streudiagramm ohne Linie. Hier können wir bereits sehen, dass eine Zunahme der Streuung bei höheren Werten erkennbar ist, weil wir einen leicht nach rechts geöffneten Trichter haben. Das zweite Diagramm hilft zusätzlich mit einer roten Linie, die bei Homoskedastizität möglichst gerade wird. Ist sie wellig oder hat sie eine positive oder negative Steigung, können wir von Heteroskedastizität ausgehen. Genauere Auskunft gibt aber der oben gerechnete Test!\n\n#### Was tun bei Heteroskedastizität der Residuen? Berechnung von HC-Standard Errors!\n\nLiegt Heteroskedastizität vor, müssen Sie nicht verzweifeln: Erstens ist die Regressionsanalyse sehr robuts gegen die Verletzung ihrer Voraussetzungen. Zweitens können wir diesen Konflikt einigermaßen elegant auflösen, indem wir pauschal **robuste Standardfehler** schätzen lassen, so dass die Verletzung nicht mehr zu Schätzfehlern führt. In R gibt es (wie immer) verschiedene Wege Heteroskedastizität zu kontern. Eine einfache Lösung bietet das *lmtest-Paket* mit der *coeftest-Funktion* in Kombination mit dem Befehl *vcov()*, der zur Berechnung von heteroscedasticity consistent (HC) standard errors führt. So ermöglichen wir die Berechnung von **heteroskedastizitätskonsistenten bzw. heteroskedastizitätsrobusten Schätzern**. Nutzen wir diese Lösung, werden die Standardfehler nicht mehr verzerrt und damit auch nicht die t-Werte und p-Werte unserer Schätzung.\n\nPS: Zur Berechnung von heteroscedasticity consistent (HC) standard errors gibt es verschiedene HC-Funktionen. Hier nutzen wir zunächst Typ 3, die auch Hayes & Cai empfehlen (Hayes, A. F., & Cai, L. (2007): Using heteroskedasticity-consistent standard error estimators in OLS regression: An introduction and software implementation. Behavior research methods, 39(4), 709-722). HC4 (die zweite Variante) ist dann sinnvoll, wenn die Residuen nicht normalverteilt sind. (Wie wir später sehen werden, ist das bei uns leider auch der Fall)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncoeftest(model, vcov = vcovHC(model, type = \"HC3\"))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nt test of coefficients:\n\n            Estimate Std. Error t value      Pr(>|t|)    \n(Intercept) 279.2690    44.7423  6.2417 0.00000001109 ***\nalter        -1.9585     0.8609 -2.2749       0.02509 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n```\n:::\n\n```{.r .cell-code}\n#coeftest(model, vcov = vcovHC(model, type = \"HC4\")) # diese Variante wählen, wenn Residuen nicht normalverteilt sind \n```\n:::\n\n\nNach der Ausführung erhalten wir eine neue Regressionstabelle. Wenn Sie diese Tabelle mit dem obigen Output unseres Regressionsmodells abgleichen, sehen Sie, dass sich die eigentlichen Koeffizienten (\"Estimates\") nicht verändert haben - aber alle Werte, die rechts davon stehen, also Standardfehler (Std. Error), t-Werte und p-Werte. Diese sind nun um unsere Schätzfehler durch Heteroskedastizität korrigiert.\n\nAlso weiter geht's!\n\n#### Prüfung der Voraussetzungen 3: Unabhängigkeit der Residuen\n\nAuch die Annahme, dass die **Residuen unabhängig** voneinander sind, ist eine wichtige Voraussetzung der Regressionsanalyse. Unabhängigkeit der Residuen bedeutet inhaltlich: Wenn ich den Fehlerterm für eine bestimmte Beobachtung kenne, darf mir das keine Information über den Fehlerterm für die nächste Beobachtung liefern. Es darf also nichts systematisch zu einer Verzerrung meiner Beobachtungen (bzw. meiner Fehlerterme) führen. Ansonsten läge eine Autokorrelation der Fehlerterme vor, die die Aussagekraft des Modells reduzieren würde.\n\nDas performance-package ist einfach soooo cool! Es beinhaltet auch die check_autocorrelation-Funktion, mit der wir diese Annahme sehr einfach prüfen können:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_autocorrelation(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: Residuals appear to be independent and not autocorrelated (p = 0.294).\n```\n:::\n:::\n\n\nAuch hier ist der Output wieder sehr klar: Die Prüfung ergibt, dass die Residuen unabhängig und nicht autokorreliert sind (p = 0,588) - sonst hätten wir auch hier einen signifikanten p-Wert erhalten. Prima!\n\n#### Prüfung der Voraussetzungen 4: Normalverteilung der Residuen\n\nWenn die Residuuen nicht der Normalverteilungskurve folgen, sondern stattdessen eigene \"Muster\" in ihrer Verteilung aufweisen, kann dies darauf hindeuten, dass wir nicht alle Prädiktoren im Modell berücksichtigt haben und somit ein Teil der erklärenden Information in die Residuen übergeht, wo sie das erkennbare Muster \"verursacht\".\n\nAuch die Voraussetzung, dass die Residuen normalverteilt sein sollen, lässt sich mit einer Funktion aus dem performance-Package sehr einfach überprüfen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_normality(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nWarning: Non-normality of residuals detected (p < .001).\n```\n:::\n:::\n\n\nAuch hier ist das Ergebnis ohne Probleme zu interpretieren, weil R hier eine \"direkte Ansage\" macht. In unserem Fall ist die Voraussetzung der Normalverteilung verletzt, weil p signifikant wird. Das müssen wir bei der Interpretation der Daten berücksichtigen. Grundsätzlich können wir hier wieder darauf verweisen, dass die Regressionsanalyse robust gegen die Verletzung ihrer Voraussetzungen ist. Eine Alternative ist, dass wir ein **Bootstrapping-Verfahren** auf unsere Daten anwenden. Das aber nur zur Info, wenn Sie hier selbstständig weitermachen wollen - das würde jetzt etwas zu weit führen :) Außerdem werden wir unten bei der zusätzlichen visuellen Inspektion mit der Funktion *check_models* auch noch sehen, dass unsere Annahme nicht allzu schlimm verletzt ist.\n\n#### Prüfung der Voraussetzungen 5: Ausreißer im Modell\n\nAusreißer sind ein Problem für viele parametrische Verfahren, denn einzelne Ausreißer können einen sonst signifikanten Trend zunichte machen (ggf. also eliminieren). Ob es in unserem Modell Ausreißer gibt, kann ich wieder mit einer sehr einfachen Funktion aus dem performance-Package prüfen, die auf das sogenannte \"cooks distance\" zurückgreift. Der Wert gibt mir Auskunft darüber, welchen Einfluss mögliche Ausreißer auf das Modell haben.\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_outliers(model)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\nOK: No outliers detected.\n- Based on the following method and threshold: cook (0.7).\n- For variable: (Whole model)\n```\n:::\n:::\n\n\nIn unserem Fall gibt es keine Ausreißer, die das Modell beinträchtigen - vielleicht hätten wir sonst auch keinen signifikanten Zusammenhang beobachten können.\n\n#### Add-on: Visuelle Inspektion der Modellgüte bzw. der Modellannahmen\n\nEs gibt im performance-Package auch eine sehr coole Funktion, die mir eine visuelle Inspektion meiner Modellgüte bzw. verschiedenen Modellannahmen erlaubt (Normalität der Residuen, Normalität der zufälligen Effekte, lineare Beziehung, Homogenität der Varianz, Multikollinearität). Mit der check_model-Funktion kann ich mir dazu mehrere Grafiken im Überblick ausgeben lassen. YEAH! :)\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_model(model)\n```\n\n::: {.cell-output .cell-output-stderr}\n```\nNot enough model terms in the conditional part of the model to check for\n  multicollinearity.\n```\n:::\n\n::: {.cell-output-display}\n![](Skript_7.3_files/figure-html/unnamed-chunk-6-1.png){width=672}\n:::\n:::\n\n\n### TEIL B: Die multiple lineare Regression\n\n#### Anwendungsbereich der multiplen linearen Regression\n\nDie **multiple lineare Regressionsanalyse** wird angewandt, wenn geprüft werden soll, ob ein (als linear vermuteter) Zusammenhang zwischen metrischen Variablen besteht. Die multiple lineare Regressionsanalyse hat das Ziel, eine abhängige Variable (y) mittels **mehrerer unabhängigen Variablen** (x1, x2, ...) zu erklären. (Zur Erinnerung: Für nur eine x-Variable nutzen wir die einfache lineare Regression)\n\nMit Hilfe der Regressionsanalyse können drei Arten von Fragestellungen untersucht werden: 1) Ursachenanalyse: Gibt es einen Zusammenhang zwischen den unabhängigen und der einen abhängigen Variable? Wie stark ist dieser? 2) Wirkungsanalyse: Wie verändert sich die abhängige Variable bei einer Änderung der unabhängigen Variablen? 3) Prognose: Können die Messwerte der abhängigen Variable durch die Werte der unabhängigen Variablen vorhergesagt werden?\n\nDie multiple Regression entspricht in ihrer Analyslogik also der einfachen linearen Regression - nur dass sie mehr als eine unabhängige Variable berücksichtigt.\n\n#### Ziel der Analyse\n\nMit Hilfe der multiplen Regression wollen wir die Annahme prüfen, dass die Variablen Alter (agea) sowie die Rezeptionszeit von politischen Nachrichten (nwspol) der Befragten einen Einfluss auf die Internetnutzung (netustm, in Minuten) haben bzw. diese erklären und vorhersagen können. Alle Variablen sind metrisch und erfüllen damit die Voraussetzung, dass eine Regression gerechnet werden kann. (Achtung: auch kategorische Variablen können bei der Regressionsanalyse eingesetzt werden, sie müssen dann aber durch Dummy-Coding passend gemacht werden).\n\n#### Modell zum Zusammenhang von Alter, politischer Nachrichtenrezeption und Internetnutzung spezifizieren und anzeigen lassen\n\nDie Berechnung der multiplen Regression unterscheidet sich nicht stark von der Berechnung der einfachen linearen Regression. In die bereits bekannte Regressionsfunktion lm() fügen wir im hinteren Teil (d.h. hinter der Tilde) einfach die zusätzliche unabhängige Variable (politische_Nachrichtenrezeption) ein, indem wir sie mit einem + Zeichen anhängen:\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_m <- lm(internetnutzung ~ alter + politische_Nachrichtenrezeption, data = daten_mod)\nsummary(lm.beta(model_m))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = internetnutzung ~ alter + politische_Nachrichtenrezeption, \n    data = daten_mod)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-203.71  -92.77  -47.73   38.81  457.27 \n\nCoefficients:\n                                Estimate Standardized Std. Error t value\n(Intercept)                     261.8715           NA    44.9628   5.824\nalter                            -2.0528      -0.2200     0.9041  -2.271\npolitische_Nachrichtenrezeption   0.2785       0.2186     0.1234   2.256\n                                    Pr(>|t|)    \n(Intercept)                     0.0000000745 ***\nalter                                 0.0254 *  \npolitische_Nachrichtenrezeption       0.0263 *  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 147 on 97 degrees of freedom\nMultiple R-squared:  0.09171,\tAdjusted R-squared:  0.07299 \nF-statistic: 4.897 on 2 and 97 DF,  p-value: 0.009415\n```\n:::\n:::\n\n\n#### Interpretation des Outputs: Was sehen wir in der Regressionstabelle?\n\nUnter Call wird zunächst noch einmal das Regresssionsmodell beschrieben, das wir hier berechnet haben. In diesem versuchen wir auf Basis des Datensatzes \"daten_mod\" die abhängige Variable \"internetnutzung\" durch die unabhängigen Variablen \"alter\" und \"politische_Nachrichtenrezeption\" zu erklären.\n\n#### Residuen\n\nUnter Resdiuen erhalten wir Informationen zur Verteilung der Residuen. Diese geben die Abweichung der beobachteten Werte von den durch das Regressionsmodell erwarteten Werten an.\n\nCoefficients: \\#### Intercept Das Intercept definiert den Schnittpunkt der Regressionsgeraden mit der y-Achse (theoretischer Wert für y, wenn x den Wert 0 annimmt).\n\n#### Estimate\n\nDie Estimates sind die unstandardisierte b-Werte. Das sind die Werte, die zur Vorhersage in die Regressionsgleichung eingetragen werden (könnten).\n\n#### Standardized\n\nDiese Estimates sind die standardisierte b-Werte. Weil wir diese über die lm.beta-Funktion standardisiert haben, lassen sich die Koeefizienten auch bei unterschiedlicher Skalierung vergleichen.\n\n#### St. error\n\nHiermit wird der Standard-Fehler der unstandardisierten b-Werte ausgegeben.\n\n#### t-value\n\nDer t-value gibt den t-Wert des Modells an (Koeffizient / Standardfehler)\n\n#### p-value\n\nDer p-value ist für uns von besonderem Interesse - das ist der Signfikanzwert des Modells (unten mit Signfikanzsschwellen) bzw. des statistischen Zusammenhangs\n\n#### R-squared\n\nAuch beide R-Werte (R2, Adjusted R2) sind von zentraler Bedeutung für die Interpretation: R2 gibt uns die erklärte Gesamtvarianz des Modells der abhängigen Variable an, also die \"Erklärungskraft\" der unabhängigen Variable Alter und politische Nachrichtenrezeption auf die abhängige Internetnutzung. Zur Interpretation bietet es sich an, R2 als Prozentwert mit 100 zu multiplizieren. Wir können hier dann daraus lesen, dass das Alter und die politische Nachrichtenrezeption etwa 20 Prozent der Varianz der Internetnutzung erklärt. Das ist nicht super viel, aber auch nicht nichts. Wir können daraus aber auch ableiten, dass - neben dem Alter - noch andere Einflussfaktoren die Internetnutzung mitbestimmen müssen. Übrigens: Das R2 könnte theoretisch maximal den Wert 1 annehmen, dann hätten wir eine 100% Erklärung der abhängigen Variable durch die unabhängige Variable (=\\> das kommt aber in der Realität aber fast nicht vor)\n\n#### Adjusted R2\n\nWie der Name schon sagt bezeichnet Adjusted R2 die Anpassung des Modells, wobei für die Anzahl der aufgenommenen Variablen korrigiert wird (\"Strafterm für viele aufgenommene Variablen\"). Das Adjusted R2 ist daher immer schlechter als R2.\n\n#### F-Statistik\n\nAuch die F-Statistik ist wichtig: Sie gibt uns nämlich die Signfikanz des Gesamtmodells an (nicht einzelner Variablen wie bei R2!)\n\n#### Inhaltliche Interpretation: Was bedeutet das jetzt also alles?\n\nDer Output zeigt uns: Das Alter hat einen negativen Einfluss auf die Internetnutzung. Je älter ein Nutzer ist, desto weniger nutzt er das Internet. Mit jeder Einheit, in der die unabhängige Variable Alter steigt (hier: mit jedem Jahr Alter), nimmt die unabhängige Variable Internetnutzung um (-4.9169) Messeinheiten (hier: Minuten) ab. Dieser Zusammenhang ist mit p \\< .05 statistisch signifikant. Diese Ergebnisse überraschen uns nicht: Den Einfluss des Alters haben wir ja letzte Woche schon überprüft. Mit der Erweiterung zur multiplen Regression können wir nun zusätzlich sagen, dass die politische Nachrichtenrezeption auch einen Einfluss auf die Internet-Nutzung hat, denn der Wert ist ebenfalls signifikant (p \\< .05)! Die F-Statistik sagt uns zusätzlich, dass auch unser Gesamtmodell signifikant ist (p-value: 0.00001239, also \\< .05).\n\n#### Erinnerung: Zusatzfunktionen zur schöneren Ergebnisdarstellung durch das Paket broom\n\n\n::: {.cell}\n\n```{.r .cell-code}\ntidy(lm.beta(model_m))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 3 × 6\n  term                         estimate std_estimate std.error statistic p.value\n  <chr>                           <dbl>        <dbl>     <dbl>     <dbl>   <dbl>\n1 (Intercept)                   262.          NA        45.0        5.82 7.45e-8\n2 alter                          -2.05        -0.220     0.904     -2.27 2.54e-2\n3 politische_Nachrichtenrezep…    0.278        0.219     0.123      2.26 2.63e-2\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nglance(model_m)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 1 × 12\n  r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC\n      <dbl>         <dbl> <dbl>     <dbl>   <dbl> <dbl>  <dbl> <dbl> <dbl>\n1    0.0917        0.0730  147.      4.90 0.00941     2  -639. 1287. 1297.\n# ℹ 3 more variables: deviance <dbl>, df.residual <int>, nobs <int>\n```\n:::\n:::\n\n\n## Multiple Regression mit Dummy-Codierung\n\n### Vorbereitung der Daten zum Zusammenhang von Alter, Bildung, Geschlecht und Internetnutzung\n\nNun wollen wir noch Geschlecht (gndr) als unabhängige Variable mit in unser Regressionsmodell aufnehmen. Bei Gender haben wir aber das Problem, dass diese Variable nicht metrisch skaliert ist! Es handelt sich vielmehr um eine kategoriale Variable. Wie Sie schon gelernt haben, können Sie diese mit einem \"Trick\" ebenfalls in die Regressionsanalyse einbringen - Sie müssen diese dann aber durch Dummy-Coding passend machen. Wir wollen uns hier mal anschauen, wie das funktioniert. Dazu müssen wir die Variable mittels mutate-Befehl erst einmal umcodieren.\n\nDurch die Dummy-Codierung wird die kategoriale Variable in zwei Gruppen übersetzt, von denen die eine mit 1 und die andere mit 0 codiert wird. Die Gruppe, der der Wert 0 zugeordnet wird, ist dann die Referenzkategorie. In unserem Beispiel Beispiel machen wir \"männlich\" zur Referenzkategorie (und codieren es mit 0 um). Der Regressionskoeffizient b gibt dann genau die Menge an, um die sich die Internetnutzung ändert, wenn sich das Geschlecht gegenüber der Referenzkategorie verändert.\n\nPS: Die Variable als numerischen Wert zu behandeln, ist in unserem Fall etwas kompliziert, weil diese eine Faktorvariable war, die wir zuerst in eine Charaktervariable umwandeln mussten.\n\n### Dummy Codierung der Variable Gender\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndaten_mod2 <- daten_mod %>%\nmutate(gender_r  = recode(gender, 'Male'='0', 'Female'='1')) %>% # Recodierung der Var Gender zur Dummy-Variable\n  mutate(gender_r = as.numeric(as.character(gender_r))) # Variable als numerischen Wert behandeln\ndaten_mod2\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 100 × 167\n        idno cntry gender alter marsts                   edubde1 eduade2 eduade3\n       <dbl> <fct> <fct>  <dbl> <fct>                    <fct>   <fct>   <fct>  \n 1 100001074 GB    Female    67 <NA>                     <NA>    <NA>    <NA>   \n 2      1044 SE    Male      62 None of these (NEVER ma… <NA>    <NA>    <NA>   \n 3  10007670 DE    Male      58 <NA>                     Fachho… Diplom… Laufba…\n 4 100002656 GB    Female    67 Legally married          <NA>    <NA>    <NA>   \n 5      1333 SE    Male      56 None of these (NEVER ma… <NA>    <NA>    <NA>   \n 6  10002266 DE    Male      21 None of these (NEVER ma… Abitur… Kein H… Kein b…\n 7 100000680 GB    Female    31 None of these (NEVER ma… <NA>    <NA>    <NA>   \n 8  10009262 DE    Female    47 None of these (NEVER ma… Mittle… Kein H… Abgesc…\n 9 100002806 GB    Male      57 None of these (NEVER ma… <NA>    <NA>    <NA>   \n10  10002009 DE    Female    76 <NA>                     Mittle… Kein H… Laufba…\n# ℹ 90 more rows\n# ℹ 159 more variables: politische_Nachrichtenrezeption <dbl>, netusoft <fct>,\n#   internetnutzung <dbl>, ppltrst <dbl>, pplfair <dbl>, pplhlp <dbl>,\n#   polintr <fct>, psppsgva <fct>, actrolga <fct>, psppipla <fct>,\n#   cptppola <fct>, trstprl <dbl>, trstlgl <dbl>, trstplc <dbl>, trstplt <dbl>,\n#   trstprt <dbl>, trstep <dbl>, trstun <dbl>, vote <fct>, prtvede1 <fct>,\n#   prtvede2 <fct>, contplt <fct>, wrkprty <fct>, wrkorg <fct>, badge <fct>, …\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\ntable(daten_mod2$gender_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\n 0  1 \n56 44 \n```\n:::\n\n```{.r .cell-code}\nsummary(daten_mod2$gender_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n   Min. 1st Qu.  Median    Mean 3rd Qu.    Max. \n   0.00    0.00    0.00    0.44    1.00    1.00 \n```\n:::\n\n```{.r .cell-code}\nclass(daten_mod2$gender_r)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n[1] \"numeric\"\n```\n:::\n:::\n\n\n### Regressionsmodell zum Zusammenhang von Alter, Nachrichtenrezeptiion, Geschlecht und Internetnutzung spezifizieren und anzeigen lassen\n\nIn die bereits bekannte Regressionsfunktion lm() fügen wir im hinteren Teil (d.h. hinter der Tilde) nun einfach die weitere unabhängige Variable gender_r ein, indem wir sie mit einem + Zeichen anhängen.\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmodel_m2 <- lm(internetnutzung ~ alter + politische_Nachrichtenrezeption + gender_r, data = daten_mod2)\nsummary(lm.beta(model_m2))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n\nCall:\nlm(formula = internetnutzung ~ alter + politische_Nachrichtenrezeption + \n    gender_r, data = daten_mod2)\n\nResiduals:\n    Min      1Q  Median      3Q     Max \n-202.12  -94.50  -51.31   32.24  471.47 \n\nCoefficients:\n                                 Estimate Standardized Std. Error t value\n(Intercept)                     265.27637           NA   45.47227   5.834\nalter                            -1.93149     -0.20696    0.92960  -2.078\npolitische_Nachrichtenrezeption   0.26651      0.20918    0.12545   2.124\ngender_r                        -18.36732     -0.06002   30.78140  -0.597\n                                   Pr(>|t|)    \n(Intercept)                     0.000000073 ***\nalter                                0.0404 *  \npolitische_Nachrichtenrezeption      0.0362 *  \ngender_r                             0.5521    \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nResidual standard error: 147.5 on 96 degrees of freedom\nMultiple R-squared:  0.09507,\tAdjusted R-squared:  0.06679 \nF-statistic: 3.362 on 3 and 96 DF,  p-value: 0.02189\n```\n:::\n:::\n\n\n### Inhaltliche Interpretation\n\nGender hat hier keinen signifikanten Einfluss auf den Internetkonsum. Wenn es einen hätte, wäre der Einfluss geringer als bei Alter und Ausbildungsjahren (ersichtlich an der Größe des standardisierten beta-Koeffizienten). Wichtig: Gender ist als eine Dummy- Variable in 0=männlich und 1=weiblich codiert, deshalb ist der Estimate hier etwas schwieriger zu lesen. Die Frauen sind als 1 codiert und stellen hier die Vergleichsgruppe zur Referenzgruppe der Männer (=0) dar.\n\nFrauen haben eine um (9,8) Minuten geringeren Internetkonsum als Männer (wobei dieser Befund statistisch ja (nicht) signifikant ist). (Nicht wundern, wenn Ihr Ergebnis leicht anders ausfällt: Der Wert variiert entsprechend der gezogenen Zufallsstichprobe.)\n\n### Vorhersage des multivariaten Modells für die tägliche Internetnutzung durch Alter, Nachrichtenrezeption und Geschlecht\n\n\n::: {.cell}\n\n```{.r .cell-code}\npredict.lm(model_m2, data.frame(alter = c(25, 75), gender_r = c(0,1), politische_Nachrichtenrezeption = c(5, 10)))\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n       1        2 \n218.3217 104.7124 \n```\n:::\n:::\n\n\n### Inhaltliche Interpretation\n\nEine männliche Person, die 25 Jahre alt ist und 5 Minuten pro Tag politische Nachrichten rezipiert hat, einen prognostizierten Internetkonsum von 293 Minuten. Eine weibliche Person, die 75 Jahre alt ist und ebenfalls 5 Minuten pro Tag politische Nachrichten rezipiert, hat einen prognostizierten Internetkonsum von 41 Minuten. (Nicht wundern, wenn Ihr Ergebnis leicht anders ausfällt: Der Wert variiert entsprechend der gezogenen Zufallsstichprobe.)\n\n### Zusätzliche Voraussetzungsprüfung bei der multiplen linearen Regression: Liegt Multikollinearität vor?\n\nDie multiple lineare Regression erfordert alle Voraussetzungen, die für die einfache Regression auch verlangt sind - wie Sie diese ausführen, haben Sie ja heute zu Anfang der Sitzung gelernt (siehe oben). Zusätzlich müssen Sie bei einer multiplen Regresssion noch prüfen, ob **Multikollinearität** vorliegt. Multikollinearität bedeutet, dass mindestens einer unserer Prädiktoren durch einen oder mehrere der anderen Prädiktoren vorhergesagt werden kann. Die Prädiktoren wären in diesem Fall nicht unabängig voneinander, sondern würden hoch miteinander korrelieren und hätten damit sozusagen keine selbstständige Erklärungskraft im Modell.\n\nOb Multikollinearität vorliegt, können wir durch den **VIF-Wert (variance inflation factor)** ermitteln. Dieser darf nicht über 10 liegen, idealerweise auch nicht über 5. Um dies zu prüfen, nutzen wir den check_collinearity-Befehl aus dem Performance package:\n\n\n::: {.cell}\n\n```{.r .cell-code}\ncheck_collinearity(model_m2)\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# Check for Multicollinearity\n\nLow Correlation\n\n                            Term  VIF    VIF 95% CI Increased SE Tolerance\n                           alter 1.05 [1.00,  3.50]         1.03      0.95\n politische_Nachrichtenrezeption 1.03 [1.00, 26.71]         1.01      0.97\n                        gender_r 1.07 [1.00,  2.29]         1.04      0.93\n Tolerance 95% CI\n     [0.29, 1.00]\n     [0.04, 1.00]\n     [0.44, 1.00]\n```\n:::\n:::\n\n\n### Inhaltliche Interpretation\n\nDie VIF-Werte liegen zwischen 0 und 5; wir können daher davon ausgehen, dass keine Multikollinearität vorliegt (grün = \"Low Correlation\").\n\n## Add-On: Weitere Plots zur (vergleichenden) Regressionsanalyse\n\n\n::: {.cell}\n\n```{.r .cell-code}\ndaten_mod3 <- daten %>% \n  select(agea, netustm, cntry) %>% \n  rename(alter = agea,\n         internetnutzung = netustm,\n         land = cntry) %>% \n  filter(land %in% c(\"DE\", \"FR\", \"IS\", \"PL\")) %>% \n  drop_na() %>% \n  group_by(land) %>% \n  slice_sample(n = 100) %>% \n  ungroup()\ndaten_mod3\n```\n\n::: {.cell-output .cell-output-stdout}\n```\n# A tibble: 200 × 3\n   alter internetnutzung land \n   <dbl>           <dbl> <fct>\n 1    59             240 DE   \n 2    35              60 DE   \n 3    38             240 DE   \n 4    20             240 DE   \n 5    51              60 DE   \n 6    64             150 DE   \n 7    60              30 DE   \n 8    28             540 DE   \n 9    21             300 DE   \n10    53              45 DE   \n# ℹ 190 more rows\n```\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nggplot(daten_mod3, aes(alter, internetnutzung, colour = land)) +\n  geom_jitter(alpha = 0.5) +\n  geom_smooth(method = lm, formula = \"y ~ x\", se = FALSE) + \n  scale_colour_brewer(palette = \"Set1\") + \n  ggtitle(\"Lineare Regression für Alter und Internetnutzung (vier Länder)\") + \n  xlab(\"Alter\") + ylab(\"tägliche Internetnutzung (Minuten)\")\n```\n\n::: {.cell-output-display}\n![](Skript_7.3_files/figure-html/Lineare Regression für Alter und Internetnutzung (vier Länder) plotten-1.png){width=672}\n:::\n:::\n",
    "supporting": [
      "Skript_7.3_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}